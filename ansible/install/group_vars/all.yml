---

# OpenStack Installer
tripleo: true

browbeat_path: /home/stack/browbeat
home_dir: /home/stack
# Configuration items to adjust browbeat results served through httpd
browbeat_results_port: 9001
browbeat_results_in_httpd: true
supported_distro: ((ansible_distribution == "CentOS" && ansible_distribution_major_version >= "7") or
                   (ansible_distribution == "RedHat" && ansible_distribution_major_version >= "7"))

# Login user for the remote hosts
host_remote_user: heat-admin
# Login user for the local/jump machine
local_remote_user: stack

# The Overcloud RC file
overcloudrc: /home/stack/overcloudrc

# The Overcloud CA cert file
# overcloud_ca_path: /etc/pki/ca-trust/source/anchors/overcloud.crt.pem

# The default Browbeat venv
browbeat_venv: /home/stack/browbeat-venv

# The default Rally venv
rally_venv: /home/stack/rally-venv

# Rally version to install
rally_version: 0.8.1

# The default Shaker venv
shaker_venv: /home/stack/shaker-venv

# Shaker version to Install
shaker_version: 0.0.17

# PerfKitBenchmarker Settings
perfkit_venv: /home/stack/perfkit-venv
perfkit_version: v1.7.0

# Guest images for the Overcloud
images:
  centos7:
    url: http://cloud.centos.org/centos/7/images/CentOS-7-x86_64-GenericCloud.qcow2
  cirros:
    url: http://download.cirros-cloud.net/0.3.4/cirros-0.3.4-x86_64-disk.img

# DNS Server to add
dns_server: 10.11.5.19

# Disables dns lookup by overcloud sshd process
disable_ssh_dns: false

# epel7 rpm for collectd packages
epel7_rpm: https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm

# Extra Repos to add during collectd install
repos:
  rhel-7-server-beta:
    baseurl: http://walkabout.foobar.com/released/RHEL-7/7.3-Beta/Server/x86_64/os/

# Host where connmond will be running
connmon_host: 192.0.2.1

########################################
# Collectd Configuration
########################################
# Install collectd from EPEL
collectd_from_epel: true
# Interval in seconds
collectd_interval: 10
# Run collectd on specific openstack nodes:
collectd_undercloud: true
collectd_controller: true
collectd_blockstorage: true
collectd_objectstorage: true
collectd_cephstorage: true
collectd_compute: true

# Collect plugins configuration:
########################
# Apache plugin
########################
# Undercloud
apache_undercloud_collectd_plugin: false
apache_undercloud_mod_status_port: 5001
# Overcloud Controller
apache_controller_collectd_plugin: false
apache_controller_mod_status_port: 5001

########################
# Ceph plugin
########################
# Overcloud Controller
ceph_controller_collectd_plugin: false
ceph_storage_collectd_plugin: false

########################
# Gnocchi backlog plugin
########################
# This should only be enabled on a single controller when monitoring Gnocchi for
# performance/scale. This plugin does create a token each interval and adds load
# to Gnocchi-api each time it polls for measurements and thus your cloud will pay
# a monitoring "tax" by enabling this plugin.
gnocchi_status_python_plugin: false
gnocchi_status_interval: 30

########################
# Keystone token count via dbi plugin
########################
keystone_undercloud_collectd_plugin: false
keystone_overcloud_collectd_plugin: false

########################
# Rabbitmq plugin
########################
rabbitmq_undercloud_collectd_plugin: false
rabbitmq_undercloud_collectd_interval: 10
rabbitmq_controller_collectd_plugin: false
rabbitmq_controller_collectd_interval: 10

# Queues to monitor message count on Undercloud
undercloud_monitored_queues:
  - "metering.sample"
  - "event.sample"

# Queues to monitor message count on Controllers
controller_monitored_queues:
  - "metering.sample"
  - "event.sample"

########################
# tail plugin
########################
# Determines if WARN/INFO messages are also counted
regex_warn: false
regex_info: false

########################################
# Docker related
# (use these if deploying graphite/carbon/grafana as containers)
########################################
persistent_carbon_data_path: /data/carbon/whisper
persistent_grafana_data_path: /data/grafana
docker_carbon_cache_port: 2003
docker_graphite_port: 8888
docker_grafana_port: 3000
carbon_cache_docker_image: kambiz/carbon-cache:0.9.15
graphite_web_docker_image: kambiz/graphite-web:0.9.15
grafana_docker_image: grafana/grafana:2.6.0

########################################
# Graphite Configuration
########################################
# Graphite Server ip address (Collectd -> Graphite server)
# you must fill out graphite_host prior to playbook execution
graphite_host: 10.12.21.1
graphite_port: 80
# Graphite prefix / Cloud name used both with graphite and grafana dashboards
graphite_prefix: jianzhu-cloud
# Graphite username and password for login on the dashboard
# credential aren't created when you deploy graphite, use manage.py
graphite_username: root
graphite_password: calvin
# List of cloud names taken by other infrastructure
# attempting to use them should fail.
forbidden_cloud_names:
  - "statsd"
  - "stats"
  - "stats_counts"

########################################
# Grafana Dashboarding Configuration
########################################
# Grafana Server IP Address/Port (Can be hosted on the Graphite server)
# you must fill out grafana_host prior to playbook execution
# If you are deploying grafana the username/password combination will be set
# (if you're using the grafana-docker playbook this does not currently work,
# it will deploy with admin/admin). If you're uploading dashboards be sure to
# set the password here to whatever it actually is.
grafana_host: 10.12.21.1
grafana_port: 3000
grafana_username: admin
grafana_password: 100yard-
# Batch number of hosts per row for all-{cpu, memory, disk, network} openstack dashboards
dashboards_batch: 20
# For use with all-{cpu, memory, disk, network} openstack dashboards, uses the graphite prefix to create dashboards for specific openstack cloud
dashboard_cloud_name: "{{graphite_prefix}}"

########################################
# StatsD Configuration
# Points at configured Graphite instance
########################################
statsd_host:
statsd_port: 8125
statsd_enabled: False

########################################
# Shaker Configuration
########################################
# Port for Shaker (5555 should suffice)
shaker_port: 5555
# Should choose m1.small or larger
shaker_flavor: m1.small
# Shaker centos image builder template
shaker_image: "{{shaker_venv}}/lib/python2.7/site-packages/shaker/resources/image_builder_templates/centos.yaml"
shaker_region: regionOne
shaker_dns_nameserver: "{{ dns_server }}"

#######################################
# Connman Configuration
#######################################
# Port for Connman
connmon_port: 5800

########################################
# Browbeat Network Configuration
########################################
# Public network that perfkit and shaker utilize
browbeat_pub_net_name: browbeat_public
browbeat_pub_subnet: 1.1.1.1/22
browbeat_pub_pool_start: 1.1.1.1
browbeat_pub_pool_end: 1.1.1.1
browbeat_pub_pool_gw: 1.1.1.1
# Private subnet
browbeat_pri_net_name: browbeat_private
browbeat_pri_subnet: 172.16.10.0/24
browbeat_pri_pool_start: 172.16.10.2
browbeat_pri_pool_end: 172.16.10.100
browbeat_pri_pool_gw: 172.16.10.1
browbeat_pri_pool_dns: 8.8.8.8

browbeat_router_name: browbeat_router

########################################
# ELK Server Variables
########################################
#
# port filebeat client grabs the client SSL certificate
# e.g. 9999
elk_server_ssl_cert_port: 8080
#
### logging backend ###
# you can pick between logstash or fluentd
# if left empty logstash will be used
### accepted options ###
# logging_backend:
# logging_backend: logstash
# logging_backend: fluentd
logging_backend:
#
### logstash options ###
logstash_syslog_port: 5044
### fluentd options ###
fluentd_syslog_port: 42185
fluentd_http_port: 9919
fluentd_debug_port: 24230
## elasticsearch local port listener
# we will enable localhost listening on TCP/9200
# due to utilizing elasticsearch connectors, general
# usage may want to disable this option due to security reasons
# in which case you should set this to false
es_ip:
es_local_port: 9200
es_listen_external: true
### kibana options ###
# change this to affect nginx-wrapped htpasswd authentication
kibana_user: admin
kibana_password: admin
es_kibana_index: .kibana
### kibana nginx ###
# add nonstandard port here for undercloud usage
# usage: port nginx listens to reverse-proxy Kibana
# e.g. 8888
nginx_kibana_port: 80
### install curator tool ###
# curator is the recommended tool for managing elasticsearch indexes
# https://www.elastic.co/guide/en/elasticsearch/client/curator/current/index.html
# default is no (set to blank) or false
# set the below variable to 'true' to activate
install_curator_tool: false
